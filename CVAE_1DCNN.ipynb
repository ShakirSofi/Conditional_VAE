{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Y98yluypCeoj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "# Keras uses TensforFlow backend as default\n",
        "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Concatenate\n",
        "from keras.layers import Conv1D,UpSampling1D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import keras.layers as layer\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "p1GrVIeAaD2r"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1,28*28).astype('float32') / 255.\n",
        "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.\n"
      ],
      "metadata": {
        "id": "2o8QpqpXLpU_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oh_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
        "y_train_oh = oh_encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_oh = oh_encoder.transform(y_test.reshape(-1, 1))\n"
      ],
      "metadata": {
        "id": "VrHR5KvzfJC6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_  = np.expand_dims(x_train, 1)\n",
        "y_train_oh  = np.expand_dims(y_train_oh, 1)"
      ],
      "metadata": {
        "id": "dhdO3GlDM9AI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_  = np.expand_dims(x_test, 1)\n",
        "y_test_oh  = np.expand_dims(y_test_oh, 1)"
      ],
      "metadata": {
        "id": "LclmRroaNNhw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_.shape, y_train_oh.shape,x_test_.shape, y_test_oh.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1v4Y8bwfNik",
        "outputId": "795a713e-2940-4805-b338-1c734d3500ce"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 1, 784), (60000, 1, 10), (10000, 1, 784), (10000, 1, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_size = 10\n",
        "z_dims = 2\n",
        "n_classes = 10\n",
        "input_img =  keras.Input(shape=(1, 28*28))\n",
        "input_cond = Input(shape=(1, n_classes))\n",
        "def sample_z(args):\n",
        "    mu, log_var = args\n",
        "    batch = K.shape(mu)[0]\n",
        "    eps = K.random_normal(shape=(z_dims, ))\n",
        "    return mu + K.exp(log_var / 2) * eps\n",
        "\n",
        "\n",
        "\n",
        "# Encoder\n",
        "traj_input  =  Concatenate(axis=-1)([input_img, input_cond])\n",
        "traj_input = layer.Conv1D(h_size, 3, activation = 'relu', padding = 'same')(traj_input)\n",
        "traj_input = layer.MaxPool1D(4, padding = 'same')(traj_input)\n",
        "traj_input = layer.Conv1D(1, 3, activation = 'relu', padding = 'same')(traj_input)\n",
        "traj_input = layer.MaxPool1D(4, padding = 'same')(traj_input)\n",
        "traj_input = layer.Flatten()(traj_input)\n",
        "\n",
        "# Sampling\n",
        "\n",
        "z_mean = layer.Dense(z_dims, activation='tanh')(traj_input)\n",
        "z_var_log = layer.Dense(z_dims, activation='linear')(traj_input)\n",
        "z = Lambda(sample_z, output_shape=(z_dims,))([z_mean, z_var_log])\n",
        "z= layer.Reshape((1, z_dims))(z)\n",
        "z_cond = Concatenate(axis=-1)([z, input_cond])\n",
        "\n",
        "# Decoder\n",
        "z_in = Input(shape=(1, z_dims,))\n",
        "cond_in = Input(shape=(1, n_classes,))\n",
        "dec_input = Concatenate(axis=-1)([z_in, cond_in])\n",
        "z_traj_input = layer.Dense(50)(dec_input)\n",
        "z_traj_input = layer.Reshape((25, 2))(z_traj_input)\n",
        "z_traj_input = layer.Conv1D(h_size, 3, activation = 'relu', padding = 'same')(z_traj_input)\n",
        "c = layer.UpSampling1D(2)(z_traj_input)\n",
        "z_traj_input =   layer.UpSampling1D(2)(z_traj_input) #layer.Conv1D(2, 1, activation = 'relu', padding = 'same')(z_traj_input)\n",
        "z_traj_input = layer.Flatten()(z_traj_input)\n",
        "z_traj_input = layer.Dense(28*28, activation='sigmoid')(z_traj_input)\n",
        "traj_hat = layer.Reshape((1, 28*28))(z_traj_input)"
      ],
      "metadata": {
        "id": "qFuBH6L_at9B"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "k7-SQTG8Aad8"
      },
      "outputs": [],
      "source": [
        "encoder = Model([input_img, input_cond], [z_mean, z_var_log, z, input_cond])\n",
        "# encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "E6xT_dtNAad8"
      },
      "outputs": [],
      "source": [
        "decoder =  Model([z_in, cond_in], traj_hat)\n",
        "# decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output= decoder(encoder([[input_img, input_cond]])[2:])"
      ],
      "metadata": {
        "id": "a_PeJouAhYI2"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(encoder_mu, encoder_log_variance):\n",
        "    def vae_reconstruction_loss(y_true, y_predict):\n",
        "        reconstruction_loss_factor = 1000\n",
        "        reconstruction_loss = tf.keras.backend.mean(tf.keras.backend.square(y_true-y_predict))\n",
        "        return reconstruction_loss_factor * reconstruction_loss\n",
        "\n",
        "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
        "        kl_loss = -0.5 * tf.keras.backend.sum(1.0 + encoder_log_variance - tf.keras.backend.square(encoder_mu) - tf.keras.backend.exp(encoder_log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_kl_loss_metric(y_true, y_predict):\n",
        "        kl_loss = -0.5 * tf.keras.backend.sum(1.0 + encoder_log_variance - tf.keras.backend.square(encoder_mu) - tf.keras.backend.exp(encoder_log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_loss(y_true, y_predict):\n",
        "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
        "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
        "\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    return vae_loss"
      ],
      "metadata": {
        "id": "1W1wP4psDNig"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvae = Model([input_img, input_cond], output)\n",
        "cvae.compile(optimizer='adam', loss=loss_func(z_mean, z_var_log), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8kISn1YJoqna"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bcrGPZ9iMY9",
        "outputId": "94e60974-4579-482b-f831-6403fd2f2c75"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_30 (InputLayer)          [(None, 1, 784)]     0           []                               \n",
            "                                                                                                  \n",
            " input_31 (InputLayer)          [(None, 1, 10)]      0           []                               \n",
            "                                                                                                  \n",
            " model_10 (Functional)          [(None, 2),          23869       ['input_30[0][0]',               \n",
            "                                 (None, 2),                       'input_31[0][0]']               \n",
            "                                 (None, 1, 2),                                                    \n",
            "                                 (None, 1, 10)]                                                   \n",
            "                                                                                                  \n",
            " model_11 (Functional)          (None, 1, 784)       393504      ['model_10[0][2]',               \n",
            "                                                                  'model_10[0][3]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 417,373\n",
            "Trainable params: 417,373\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "cvae.fit([x_train_, y_train_oh], x_train_ ,\n",
        "       shuffle=True,\n",
        "       epochs=10,\n",
        "       batch_size=64,\n",
        "       verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABwOuKxxqqa2",
        "outputId": "41252af6-e106-49df-f6e4-ebeabaf2b6f5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 16s 16ms/step - loss: 59.3337 - accuracy: 0.0124\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 53.7612 - accuracy: 0.0142\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 53.6629 - accuracy: 0.0144\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 53.6285 - accuracy: 0.0147\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 53.5883 - accuracy: 0.0141\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 53.5711 - accuracy: 0.0146\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 53.5529 - accuracy: 0.0143\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 53.5395 - accuracy: 0.0143\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 53.5280 - accuracy: 0.0145\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 53.5187 - accuracy: 0.0145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcbe7e9b490>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = 5\n",
        "pred_class = np.array(oh_encoder.transform([[num_class]])).reshape(1,1,-1)\n",
        "pred_noise = np.random.randn(1, z_dims).reshape(1,1,-1)\n",
        "pred_out = decoder.predict([pred_noise, pred_class])"
      ],
      "metadata": {
        "id": "lswqmcmB8Xp8"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digit = pred_out.reshape(28, 28)"
      ],
      "metadata": {
        "id": "nh_vVCUskpxd"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(digit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "_xBQ69TJF7Cw",
        "outputId": "d023aca1-9b50-432b-8f95-c32ea733fe3b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcbe2f3e750>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}